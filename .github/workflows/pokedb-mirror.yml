name: Mirror PokeDB Open Data

on:
  schedule:
    # 毎日UTC 0:00に実行 (日本時間 9:00)
    - cron: '0 0 * * *'
  workflow_dispatch: # 手動実行も可能

jobs:
  mirror:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: |
          pip install requests beautifulsoup4 lxml
          
      - name: Download files
        run: |
          python3 << 'EOF'
          import requests
          from bs4 import BeautifulSoup
          import time
          import os
          from urllib.parse import urljoin
          
          # ページからリンクを取得
          base_url = "https://sv.pokedb.tokyo/guide/opendata"
          response = requests.get(base_url)
          soup = BeautifulSoup(response.content, 'html.parser')
          
          # data ディレクトリを作成
          os.makedirs('data', exist_ok=True)
          
          # CSV と JSON ファイルのリンクを探す
          downloaded_files = []
          
          for link in soup.find_all('a', href=True):
              href = link['href']
              # opendata/ 配下の .csv または .json ファイルを対象
              if '/opendata/' in href and (href.endswith('.csv') or href.endswith('.json')):
                  file_url = urljoin(base_url, href)
                  filename = os.path.basename(href)
                  filepath = os.path.join('data', filename)
                  
                  print(f"Downloading: {file_url}")
                  
                  try:
                      file_response = requests.get(file_url, timeout=30)
                      file_response.raise_for_status()
                      
                      with open(filepath, 'wb') as f:
                          f.write(file_response.content)
                      
                      print(f"Saved: {filepath}")
                      downloaded_files.append(filename)
                      
                      # 10秒待機
                      if len(downloaded_files) < len([l for l in soup.find_all('a', href=True) if '/opendata/' in l['href']]):
                          print("Waiting 10 seconds...")
                          time.sleep(10)
                          
                  except Exception as e:
                      print(f"Error downloading {file_url}: {e}")
          
          print(f"\nTotal files downloaded: {len(downloaded_files)}")
          for f in downloaded_files:
              print(f"  - {f}")
          EOF
          
      - name: Check for changes
        id: check_changes
        run: |
          git add data/
          if git diff --staged --quiet; then
            echo "changed=false" >> $GITHUB_OUTPUT
          else
            echo "changed=true" >> $GITHUB_OUTPUT
          fi
          
      - name: Commit and push if changed
        if: steps.check_changes.outputs.changed == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git commit -m "Update PokeDB data - $(date +'%Y-%m-%d %H:%M:%S')"
          git push
          
      - name: No changes detected
        if: steps.check_changes.outputs.changed == 'false'
        run: |
          echo "No changes detected in data files."